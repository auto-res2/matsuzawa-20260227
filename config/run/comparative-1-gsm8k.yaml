# Comparative baseline 1: Standard hidden CoT (single call)
run_id: comparative-1-gsm8k

# [VALIDATOR FIX - Attempt 3]
# [PROBLEM]: Model produces incorrect answers (0% accuracy)
# [CAUSE]: normalize_number extracts first number in text; with reasoning, it extracts wrong number
# [FIX]: Structured prompt with delimiter so extraction finds the final answer, not reasoning numbers
#
# [OLD CODE]:
# method:
#   type: hidden_cot
#   name: "Hidden CoT"
#   description: "Single call with hidden chain-of-thought instruction"
#   max_calls: 1
#   prompt: "Answer with ONLY a number. No words, explanations, or units - just the number."
#
# [NEW CODE]:
method:
  type: hidden_cot
  name: "Hidden CoT"
  description: "Single call with hidden chain-of-thought instruction"
  max_calls: 1
  prompt: "Solve this problem step-by-step. After your reasoning, write 'ANSWER:' followed by only the final numeric answer.\n\nQuestion:"

# [VALIDATOR FIX - Attempt 3]
# [PROBLEM]: max_tokens=10 is too restrictive and may truncate reasoning or answers
# [CAUSE]: With hidden CoT, model needs space to think internally even if output is just a number
# [FIX]: Increased max_tokens to 512 to allow internal reasoning space
#
# [OLD CODE]:
# model:
#   provider: openai
#   model_name: gpt-4o-mini
#   temperature: 0.0
#   max_tokens: 10  # Very low to force number-only output
#
# [NEW CODE]:
model:
  provider: openai
  model_name: gpt-4o-mini
  temperature: 0.0
  max_tokens: 512  # Allow space for internal reasoning while still expecting numeric output

dataset:
  name: gsm8k
  split: test
  num_samples: 200
  shuffle_seed: 42

inference:
  batch_size: 1
  num_workers: 1

wandb:
  tags: ["comparative", "hidden-cot", "gsm8k"]
